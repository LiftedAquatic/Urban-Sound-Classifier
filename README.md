# Urban-Sound-Classifier
## Employing Deep Learning to classify sounds from an urban environment 

This project was a fascinating experience. After months of charting the unfamiliar territory of machine learning models, it was nice to feel at home working with audio. The methods for extracting features from sound are rooted in familiar concepts dealing with musical scales, tonal profiles and gain structure. I was able to expand on my previous knowledge and learn about Mel-Frequency Cepstrum Coefficients and how one can create a traceable image from a sound. Going into the project I didn’t expect that audio classification would quickly morph into image classification. Convolutional Neural Networks are clearly powerful and expansive. I learned about CNN model architecture and the purpose of each fundamental component. Deep Learning they say is a black box, as it’s hard to trace the exact mechanism at play between the hidden layers. But it’s still a process with a degree of wieldiness. A method of harnessing computational power that I will continue to explore.  

Link to dataset: https://urbansounddataset.weebly.com/urbansound8k.html

Thank you to Mick Smales. He worked with the same dataset and the article below helped serve as a guide. I used pieces of his code in my preprocessing-modeling notbook. Article: https://mikesmales.medium.com/sound-classification-using-deep-learning-8bc2aa1990b7 

Thank you to Papia Nandi. Her article on sound classification helped me quite a bit. I used pieces of her code as well. 
Article: https://towardsdatascience.com/cnns-for-audio-classification-6244954665ab

Thank you to my mentor Jeremy Cunningham for the advice and encouragement. 
